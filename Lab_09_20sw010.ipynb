{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNzMcTOw+QjX4oQtSXf9xT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalmemon124/Data-Science/blob/main/Lab_09_20sw010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0DKEnQO8_kq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIbGbimNxTr2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import datetime\n",
        "import numpy as np\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon=pd.read_csv('/content/pokemon.csv')"
      ],
      "metadata": {
        "id": "ZjlGaxDlxZ7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population=pd.read_csv('/content/population_data.csv')\n"
      ],
      "metadata": {
        "id": "ZMDx3DWoxaNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rural = pd.read_csv('rural_population_percent.csv', skiprows=4)\n",
        "df_electricity = pd.read_csv('electricity_access_percent.csv', skiprows=4)\n",
        "\n",
        "# TODO: remove the 'Unnamed:62' column from each data set\n",
        "df_rural.drop('Unnamed: 62', axis=1, inplace=True)\n",
        "df_electricity.drop('Unnamed: 62', axis=1, inplace=True)\n",
        "\n",
        "# TODO: combine the two data sets together using the concat method\n",
        "df = pd.concat([df_rural, df_electricity])\n",
        "pd.concat"
      ],
      "metadata": {
        "id": "W2qKlmLFxab6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rural_melt = pd.melt(df_rural,\\\n",
        "                        id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'],\\\n",
        "                       var_name = 'Year', value_name='Rural_Value')\n",
        "df_electricity_melt = pd.melt(df_electricity,\\\n",
        "                              id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'],\\\n",
        "                             var_name='Year', value_name='Electricity_Value')\n",
        "\n",
        "# TODO: drop any columns from the data frames that aren't needed\n",
        "df_rural_melt.drop(['Indicator Name', 'Indicator Code'], axis=1, inplace=True)\n",
        "df_electricity_melt.drop(['Indicator Name', 'Indicator Code'], axis=1, inplace=True)\n",
        "\n",
        "# TODO: merge the data frames together based on their common columns\n",
        "# in this case, the common columns are Country Name, Country Code, and Year\n",
        "df_merge = df_rural_melt.merge(df_electricity_melt, how='outer',\\\n",
        "                               on=['Country Name', 'Country Code', 'Year'])\n",
        "\n",
        "# TODO: sort the results by country and then by year\n",
        "df_combined = df_merge.sort_values(['Country Name', 'Year'])\n",
        "df_combined"
      ],
      "metadata": {
        "id": "_CX79XLTxald"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_projects = pd.read_csv('/content/projects_data.csv', dtype=str)"
      ],
      "metadata": {
        "id": "FOZouJ7txauB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_projects.head()"
      ],
      "metadata": {
        "id": "qzUj17huxa2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_projects.isnull().sum()\n"
      ],
      "metadata": {
        "id": "bi8zwdJwxbDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/population_data.csv')\n",
        "for i in range(10):\n",
        "    line = f.readline()\n",
        "    print('line: ', i,  line)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "KIsCo6CTxbOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population.head()"
      ],
      "metadata": {
        "id": "6TTs6h15xbWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population.isnull().sum(axis=1)"
      ],
      "metadata": {
        "id": "JU4rCtaqxbcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population.columns"
      ],
      "metadata": {
        "id": "iQutXkGZuypG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population[population.isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "NdXPuziquyra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read in the projects data set and do some basic wrangling\n",
        "projects = pd.read_csv('/content/projects_data.csv', dtype=str)\n",
        "projects.drop('Unnamed: 56', axis=1, inplace=True)\n",
        "projects['totalamt'] = pd.to_numeric(projects['totalamt'].str.replace(',', ''))\n",
        "projects['countryname'] = projects['countryname'].str.split(';', expand=True)[0]\n",
        "projects['boardapprovaldate'] = pd.to_datetime(projects['boardapprovaldate'])\n",
        "\n",
        "# Filter the data frame for projects over 1 billion dollars\n",
        "projects_over_1_billion = projects[projects['totalamt'] > 1000000000]  # 1 billion dollars = 1,000,000,000\n",
        "\n",
        "# Count the number of unique countries in the results\n",
        "unique_countries_count = projects_over_1_billion['countryname'].nunique()\n",
        "\n",
        "print(\"Number of countries with projects over 1 billion dollars:\", unique_countries_count)"
      ],
      "metadata": {
        "id": "_kP-e8abuyvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Read in the projects data set\n",
        "projects = pd.read_csv('/content/projects_data.csv', dtype=str)\n",
        "projects.drop('Unnamed: 56', axis=1, inplace=True)\n",
        "projects['totalamt'] = pd.to_numeric(projects['totalamt'].str.replace(',', ''))\n",
        "projects['boardapprovaldate'] = pd.to_datetime(projects['boardapprovaldate'])\n",
        "\n",
        "# Define the list of countries\n",
        "countries_of_interest = ['Bosnia and Herzegovina', 'Croatia', 'Kosovo', 'Macedonia', 'Serbia', 'Slovenia']\n",
        "\n",
        "# Make the comparison date timezone-aware\n",
        "comparison_date = pd.Timestamp(datetime.datetime(1992, 4, 27), tz='UTC')\n",
        "\n",
        "# Filter the data frame for projects meeting the criteria\n",
        "republics = projects[(projects['boardapprovaldate'] < comparison_date) & (projects['countryname'].isin(countries_of_interest))]\n",
        "\n",
        "# Keep only the specified columns\n",
        "republics = republics[['regionname', 'countryname', 'lendinginstr', 'totalamt', 'boardapprovaldate',\n",
        "                      'location', 'GeoLocID', 'GeoLocName', 'Latitude', 'Longitude', 'Country', 'project_name']]\n",
        "\n",
        "# Sort the results by boardapprovaldate\n",
        "republics = republics.sort_values(by='boardapprovaldate')\n",
        "\n",
        "# Show the results\n",
        "print(republics)"
      ],
      "metadata": {
        "id": "c-Ak-wb0uyyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Read in the projects data set\n",
        "projects = pd.read_csv('/content/projects_data.csv', dtype=str)\n",
        "projects.drop('Unnamed: 56', axis=1, inplace=True)\n",
        "projects['totalamt'] = pd.to_numeric(projects['totalamt'].str.replace(',', ''))\n",
        "projects['boardapprovaldate'] = pd.to_datetime(projects['boardapprovaldate'])\n",
        "\n",
        "# Define the start and end dates for Yugoslavia projects\n",
        "start_date = pd.Timestamp(datetime.datetime(1980, 2, 1), tz='UTC')\n",
        "end_date = pd.Timestamp(datetime.datetime(1989, 5, 23), tz='UTC')\n",
        "\n",
        "# Filter the data frame for Yugoslavia projects within the specified date range\n",
        "yugoslavia = projects[(projects['boardapprovaldate'] >= start_date) & (projects['boardapprovaldate'] <= end_date) & (projects['countryname'] == 'Yugoslavia')]\n",
        "\n",
        "# Keep only the specified columns\n",
        "yugoslavia = yugoslavia[['regionname', 'countryname', 'lendinginstr', 'totalamt', 'boardapprovaldate',\n",
        "                      'location', 'GeoLocID', 'GeoLocName', 'Latitude', 'Longitude', 'Country', 'project_name']]\n",
        "\n",
        "# Sort the results by boardapprovaldate\n",
        "yugoslavia = yugoslavia.sort_values(by='boardapprovaldate')\n",
        "\n",
        "# Show the results\n",
        "print(yugoslavia)\n"
      ],
      "metadata": {
        "id": "J4TCUgZmuy0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "projects = pd.read_csv('/content/projects_data.csv', dtype=str)\n",
        "projects.drop('Unnamed: 56', axis=1, inplace=True)\n",
        "projects['totalamt'] = pd.to_numeric(projects['totalamt'].str.replace(',', ''))\n",
        "projects['boardapprovaldate'] = pd.to_datetime(projects['boardapprovaldate'])\n",
        "\n",
        "start_date_yugoslavia = pd.Timestamp(datetime.datetime(1980, 2, 1), tz='UTC')\n",
        "end_date_yugoslavia = pd.Timestamp(datetime.datetime(1989, 5, 23), tz='UTC')\n",
        "\n",
        "yugoslavia = projects[(projects['boardapprovaldate'] >= start_date_yugoslavia) &\n",
        "                      (projects['boardapprovaldate'] <= end_date_yugoslavia) &\n",
        "                      (projects['countryname'] == 'Yugoslavia')]\n",
        "\n",
        "countries_of_interest = ['Bosnia and Herzegovina', 'Croatia', 'Kosovo', 'Macedonia', 'Serbia', 'Slovenia']\n",
        "\n",
        "# Make the comparison date timezone-aware\n",
        "comparison_date = pd.Timestamp(datetime.datetime(1992, 4, 27), tz='UTC')\n",
        "\n",
        "republics = projects[(projects['boardapprovaldate'] < comparison_date) &\n",
        "                     (projects['countryname'].isin(countries_of_interest))]\n",
        "\n",
        "selected_columns = ['regionname', 'countryname', 'lendinginstr', 'totalamt', 'boardapprovaldate',\n",
        "                      'location', 'GeoLocID', 'GeoLocName', 'Latitude', 'Longitude', 'Country', 'project_name']\n",
        "yugoslavia = yugoslavia[selected_columns]\n",
        "republics = republics[selected_columns]\n",
        "\n",
        "concatenated_data = pd.concat([yugoslavia, republics])\n",
        "\n",
        "unique_dates = concatenated_data['boardapprovaldate'].unique()\n",
        "date_counts = concatenated_data['boardapprovaldate'].value_counts()\n",
        "dates_appeared_twice = date_counts[date_counts == 2]\n",
        "\n",
        "print(dates_appeared_twice)"
      ],
      "metadata": {
        "id": "8vKXLfmFvaKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# run this code cell to see the duplicate data\n",
        "pd.concat([yugoslavia[yugoslavia['boardapprovaldate'] == datetime.date(1983, 7, 26)], republics[republics['boardapprovaldate']"
      ],
      "metadata": {
        "id": "ybK3ptwwvahI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# read in the projects data set and do basic wrangling\n",
        "gdp = pd.read_csv('/content/gdp_data.csv', skiprows=4)\n",
        "gdp.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
        "population = pd.read_csv('/content/population_data.csv', skiprows=4)\n",
        "population.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
        "\n",
        "\n",
        "# Reshape the data sets so that they are in long format\n",
        "gdp_melt = gdp.melt(id_vars=['Country Name'],\n",
        "                    var_name='year',\n",
        "                    value_name='gdp')\n",
        "\n",
        "# Use back fill and forward fill to fill in missing gdp values\n",
        "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "population_melt = population.melt(id_vars=['Country Name'],\n",
        "                                  var_name='year',\n",
        "                                  value_name='population')\n",
        "\n",
        "# Use back fill and forward fill to fill in missing population values\n",
        "population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# merge the population and gdp data together into one data frame\n",
        "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))\n",
        "\n",
        "# filter data for the year 2016\n",
        "df_2016 = df_country[df_country['year'] == '2016']\n",
        "\n",
        "# filter out values that are not countries\n",
        "non_countries = ['World',\n",
        " 'High income',\n",
        " 'OECD members',\n",
        " 'Post-demographic dividend',\n",
        " 'IDA & IBRD total',\n",
        " 'Low & middle income',\n",
        " 'Middle income',\n",
        " 'IBRD only',\n",
        " 'East Asia & Pacific',\n",
        " 'Europe & Central Asia',\n",
        " 'North America',\n",
        " 'Upper middle income',\n",
        " 'Late-demographic dividend',\n",
        " 'European Union',\n",
        " 'East Asia & Pacific (excluding high income)',\n",
        " 'East Asia & Pacific (IDA & IBRD countries)',\n",
        " 'Euro area',\n",
        " 'Early-demographic dividend',\n",
        " 'Lower middle income',\n",
        " 'Latin America & Caribbean',\n",
        " 'Latin America & the Caribbean (IDA & IBRD countries)',\n",
        " 'Latin America & Caribbean (excluding high income)',\n",
        " 'Europe & Central Asia (IDA & IBRD countries)',\n",
        " 'Middle East & North Africa',\n",
        " 'Europe & Central Asia (excluding high income)',\n",
        " 'South Asia (IDA & IBRD)',\n",
        " 'South Asia',\n",
        " 'Arab World',\n",
        " 'IDA total',\n",
        " 'Sub-Saharan Africa',\n",
        " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
        " 'Sub-Saharan Africa (excluding high income)',\n",
        " 'Middle East & North Africa (excluding high income)',\n",
        " 'Middle East & North Africa (IDA & IBRD countries)',\n",
        " 'Central Europe and the Baltics',\n",
        " 'Pre-demographic dividend',\n",
        " 'IDA only',\n",
        " 'Least developed countries: UN classification',\n",
        " 'IDA blend',\n",
        " 'Fragile and conflict affected situations',\n",
        " 'Heavily indebted poor countries (HIPC)',\n",
        " 'Low income',\n",
        " 'Small states',\n",
        " 'Other small states',\n",
        " 'Not classified',\n",
        " 'Caribbean small states',\n",
        " 'Pacific island small states']\n",
        "\n",
        "# remove non countries from the data\n",
        "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]\n",
        "\n",
        "\n",
        "# show the first ten rows\n",
        "print('first ten rows of data')\n",
        "df_2016.head(10)\n"
      ],
      "metadata": {
        "id": "25hQs0tSvarR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def x_min_max(data):\n",
        "    # TODO: Complete this function called x_min_max()\n",
        "    # The input is an array of data as an input\n",
        "    # The outputs are the minimum and maximum of that array\n",
        "    minimum = min(data)\n",
        "    maximum = max(data)\n",
        "    return minimum, maximum\n",
        "    x_min_max(df_2016['gdp'])\n",
        "\n",
        "\n",
        "def normalize(x, x_min, x_max):\n",
        "    # Normalize the value x within the range [x_min, x_max] to the range [0, 1]\n",
        "    return (x - x_min) / (x_max - x_min)\n"
      ],
      "metadata": {
        "id": "_h-xIj8qvaz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Normalizer():\n",
        "    def __init__(self, dataframe):\n",
        "        self.params = []\n",
        "\n",
        "        # Iterate through each column in the DataFrame\n",
        "        for column in dataframe.columns:\n",
        "            # Calculate the minimum and maximum values for each column\n",
        "            x_min, x_max = self.x_min_max(dataframe[column])\n",
        "            self.params.append((x_min, x_max))\n",
        "\n",
        "    def x_min_max(self, data):\n",
        "        # Calculate the minimum and maximum values for a given data column\n",
        "        minimum = min(data)\n",
        "        maximum = max(data)\n",
        "        return minimum, maximum\n",
        "\n",
        "    def normalize_data(self, x):\n",
        "        # Normalize a data point 'x' based on the calculated parameters\n",
        "        normalized = []\n",
        "        for i, value in enumerate(x):\n",
        "            x_max = self.params[i][1]\n",
        "            x_min = self.params[i][0]\n",
        "            normalized.append((value - x_min) / (x_max - x_min))\n",
        "        return normalized\n",
        "\n"
      ],
      "metadata": {
        "id": "KsMhCOfdwDxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdp_normalizer = Normalizer(df_2016[['gdp', 'population']])"
      ],
      "metadata": {
        "id": "KrOwolbfwGA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gdp_normalizer.params\n"
      ],
      "metadata": {
        "id": "C6uYWrrRwIhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gdp_normalizer.normalize_data([13424475000000.0, 1300000000])\n"
      ],
      "metadata": {
        "id": "2VaUzWXdwLrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "gdp = pd.read_csv('/content/gdp_data.csv', skiprows=4)\n",
        "gdp.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
        "population = pd.read_csv('/content/population_data.csv', skiprows=4)\n",
        "population.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
        "\n",
        "gdp_melt = gdp.melt(id_vars=['Country Name'],\n",
        "                    var_name='year',\n",
        "                    value_name='gdp')\n",
        "\n",
        "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "population_melt = population.melt(id_vars=['Country Name'],\n",
        "                                  var_name='year',\n",
        "                                  value_name='population')\n",
        "\n",
        "population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))\n",
        "\n",
        "df_2016 = df_country[df_country['year'] == '2016']\n",
        "\n",
        "non_countries = ['World', 'High income', ...]\n",
        "\n",
        "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]\n",
        "df_2016.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "CKwUNeLpwdd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "50r6h9dbwfoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_lines(file):\n",
        "    while True:\n",
        "        line = file.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        yield line\n"
      ],
      "metadata": {
        "id": "f4lc9b_ewo6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_indicator_data(data, colnames):\n",
        "    for i, datum in enumerate(data):\n",
        "        data[i] = datum.replace('\"', '')\n",
        "\n",
        "    country = None\n",
        "\n",
        "    non_countries = ['World', 'High income', ...]\n",
        "    if country not in non_countries:\n",
        "        data_array = None\n",
        "        data_array = None\n",
        "        df = None\n",
        "        df_melt = None\n",
        "        results = []\n",
        "        return results"
      ],
      "metadata": {
        "id": "gIavcaVzwrBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_indicator_data(results):\n",
        "    conn = None\n",
        "    cur = None\n",
        "\n",
        "    if results:\n",
        "        for result in results:\n",
        "            countryname, countrycode, year, gdp = None\n",
        "            sql_string = None\n",
        "            try:\n",
        "                cur.execute(sql_string)\n",
        "            except Exception as e:\n",
        "                print('error occurred:', e, result)\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return None\n",
        "\n"
      ],
      "metadata": {
        "id": "L3zJ6edzwu6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Open the data file\n",
        "with open('/content/projects_data.csv') as f:\n",
        "    for line in extract_lines(f):\n",
        "        data = line.split(',')\n",
        "        if len(data) == 63:\n",
        "            if data[0] == '\"Country Name\"':\n",
        "                colnames = []\n",
        "                for i, datum in enumerate(data):\n",
        "                    colnames.append(datum.replace('\"', ''))\n"
      ],
      "metadata": {
        "id": "zWV8Tfu-wxGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Execute this code cell to run the ETL pipeline\n",
        "# You do not need to change anything in this cell\n",
        "\n",
        "# open the data file\n",
        "with open('../content/gdp_data.csv') as f:\n",
        "    # execute the generator to read in the file line by line\n",
        "    for line in extract_lines(f):\n",
        "        # split the comma separated values\n",
        "        data = line.split(',')\n",
        "        # check the length of the line because the first four lines of the csv file are not data\n",
        "        if len(data) == 63:\n",
        "            # check if the line represents column names\n",
        "            if data[0] == '\"Country Name\"':\n",
        "                colnames = []\n",
        "                # get rid of quote marks in the results to make the data easier to work with\n",
        "                for i, datum in enumerate(data):\n",
        "                    colnames.append(datum.replace('\"',''))\n",
        "            else:\n",
        "                # transform and load the line of indicator data\n",
        "                results = transform_indicator_data(data, colnames)"
      ],
      "metadata": {
        "id": "bvc9HEQnwzrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}